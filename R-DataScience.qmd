---
title: "R Notes"
format: html
editor: visual
---

## Manipulating Data - dplyr

**Background Information about dplyr:**

plyr (split-apply-combine strategy for data analysis) is the root of dplyr. Plyr covers a diverse set of inputs and outputs (eg. arrays, data frames, lists), dplyr only focuses on data frames, "tibbles".

**Using filter to subset data row-wise:**

We take dataset gapminder for example, canada \<- gapminder \[241:252, \]. This is a terrible idea, because 1) It's not self-documenting, there's no special about rows 241 to 252 and 2) It's fragile, if someone changes the row order, then line of code produce different results. Instead, you can use filter.

```{r}
# load tydyverse to load dplyr
library (tidyverse)
# load sample dataset - gapminder
library (gapminder)
# load sample dataset - flights
library(nycflights13)
```

```{r}
# Filter takes logical expressions and returns the rows which all are TRUE
# Filter lifeExp < 29
filter (gapminder, lifeExp < 29)
# Filter Rwanda coutry with year > 1979
filter (gapminder, country == "Rwanda", year > 1979)
# Filter both Rwanda and Afghanistan countries
filter (gapminder, country %in% c("Rwanda", "Afghanistan"))
```

### Row-wise

**Using select to subset data row-wise:**

```{r}
# select () allows to subset the data on varaibles or columns
select(gapminder, year, lifeExp)
# pipe operator with select ()
gapminder %>%
  select(year, lifeExp) %>%
  head(4)
# Now using both select() and filter ()
gapminder %>%
  filter(country == "Cambodia") %>%
  select(year, lifeExp)
```

**Using arrange() to row-order data in a principled way:**

```{r}
# arrange() reorders the rows in a data frame.Imagine you wanted this data ordered by year then country, as opposed to by country then year.
my_gap %>%
  arrange(year, country)
# Want just the data from 2007, sorted on life expectancy
my_gap %>%
  filter(year == 2007) %>%
  arrange(lifeExp)
# desc() for descending order
my_gap %>%
  filter(year == 2007) %>%
  arrange(desc(lifeExp))
```

### Column-wise

**Using mutate() to add new variables:**

```{r}
# mutate() is a function that defines and inserts new variables into a tibble
my_gap %>%
  mutate(gdp=pop*gdpPercap)

ctib <- my_gap %>%
  filter(country=="Canada")

my_gap <- my_gap %>%
  mutate(tmp=rep(ctib$gdpPercap, nlevels(country)),
         gdpPercapRel = gdpPercap/tmp,
         tmp = NULL)
my_gap
summary(my_gap$gdpPercapRel)
# Thus, I perceive Canada to be a “high GDP” country. 
```

**Rename variables - rename():**

```{r}
# rename (new name = old name)
my_gap %>%
  rename(life_exp = lifeExp,
         gdp_percap = gdpPercap,
         gdp_percap_rel = gdpPercapRel)

```

**Select certain columns - select():**

```{r}
# selcet (new name = old name)
my_gap %>%
  filter(country == "Burrundi", year >1996) %>%
  # select() can also use to rename the varaibles you request to keep
  select(yr=year, lifeExp, gdpPercap) %>%
  # this helps hoist a variable (gdpPercap) up to the front of the tibble.
  select(gdpPercap, everything())
# starts_with("abc"): matches names that begin with “abc”.
# ends_with("xyz"): matches names that end with “xyz”.
# contains("ijk"): matches names that contain “ijk”.
# num_range("x", 1:3): matches x1, x2 and x3.
```

**Move variables to the front - relocate():**

```{r}
# Use relocate() to move variables around. You might want to collect related variables together or move important variables to the front.
flights %>%
  relocate(time_hour, air_time)
```

**group_by() & summarize():**

```{r}
# group_by() adds extra structure to your dataset, grouping information which lays the groundwork for computations within the groups
# summarize() takes a dataset with n observations, computes requested summaries, and return a dataset with 1 observation 
my_gap %>%
  group_by(continent) %>%
  summarize(n=n())
# Option 2 - tally() function is a convenience function that knows to count rows
my_gap %>%
  group_by(continent) %>%
  tally()
# Option 3 - count() function is an even more convenient function that does both grouping and counting.
my_gap %>%
  count(continent)
# Differentiate by continents, count number of rows for each continent as n by using n() and count how many distinct countries in each continent as n_countries by using n_dictinct()
my_gap %>%
  group_by(continent) %>%
  summarize(n=n(),
            n_countries = n_dictinct(country))
```

**General Summarization:**

The functions you'll apply within `summarize()` include classical statistical summaries, like `mean()`, `median()`, `var()`, `sd()`, `mad()`, `IQR()`, `min()`, and `max()`. Remember they are functions that take n inputs and distill them down into 1 output.

```{r}
# Compute the average life expectancy by continent
my_gap %>%
  group_by (continent) %>%
  summarize(avg_lifeExp = mean(lifeExp))

# Summarize_at() applies the same summary function(s) to multiple variables.
# summarize_at(.tbl, .vars, .funs, ..., .cols = NULL)
# Compute average and median life expectancy and GDP per capita by continent by year…but only for 1952 and 2007.
my_gap %>%
  filter(year %in% c(1952, 2007)) %>%
# apply a summarise function to calculate the mean of a variable, without group_by, it will calculate the mean for that variable across the entire dataset. With group_by(continent, year), it calculates the mean for each combination of continent and year separately.
  group_by (continent, year) %>%
  summarize_at(vars(lifeExp, gdpPercap), list(~mean(.), ~median(.)))

# Let’s focus just on Asia. What are the minimum and maximum life expectancies seen by year.
my_gap %>%
  filter(continent == "Asia") %>%
  group_by(year) %>%
  summarize(min_lifeExp = min(lifeExp), max_lifeExp = max(lifeExp))
```

**Others Important Points:**

```{r}
# Identified the class of a dataframe
class (gapminder)
# To turn any dataframe into a tibble use as_tibble ()
as_tibble(iris)
# head () allows you to check first couple of lines of dataframe
head (gapminder)
head (gapminder,3)
# Pipe Operator  
gapminder %>%
  head (3)
# Creating a copy of dataset before making changes on that to prevent damaging
my_gap <- gapminder
# rep(x, times) is a function used to repeat the elements of x, times number of times.
my_gap <- my_gap %>%
  mutate(tmp=rep(ctib$gdpPercap, nlevels(country)))
# & represents and, | represents or
# na.rm = TRUE VS. na.rm = FALSE
# na.rm = TRUE: tells the function to remove (or ignore) the NA values when performing calculations or operations.
# na.rm = FALSE: this means that the function will not remove the NA values. In many cases, this will result in the function returning NA if there are any NA values in the data. 
```

## Graphing - ggplot

ggplot2 is one of the package of tidyverse.

```{r}
print(mpg)
```

### Scatter-PLots

```{r}
# To plot mpg, run this code to put displ (car's engine size, in litres) on the x-axis and hwy (car's fuel efficiency on the highway) on the y-axis:
# The graphing template for making graphs with ggplot2
# ggplot(data=<DATA>) + 
# <GEOM_FUNCTION> (mapping = aes(<MAPPINGS>))
ggplot(data=mpg) + 
  geom_point(mapping = aes(x=displ, y=hwy))
# "hwy"和"displ"的值被取整，因此点会出现在网格上，许多点彼此重叠。这个问题被称为过度绘制（overplotting). You can avoid this gridding by setting the position adjustment to “jitter”. position = "jitter" adds a small amount of random noise to each point.
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy), position = "jitter")
# Mapping the aesthetics in your plot to the variables in your dataset; in aes, map the colors of your points to the class variable to reveal the class of each car.
ggplot(data=mpg) + 
  geom_point(mapping = aes(x=displ, y=hwy, color=class))
# Mapped class to the size aesthetic in the same way. 
ggplot(data=mpg) + 
  geom_point(mapping = aes(x=displ, y=hwy, size=class))
# alpha= controls the transparency of the points
ggplot(data=mpg) +
  geom_point(mapping = aes(x=displ, y=hwy, alpha=class))
# shape= controls the transparency of the points
ggplot(data=mpg) +
  geom_point(mapping=aes(x=displ, y=hwy, shape=class))
```

Set aesthetic properties of your geom manually, color = ? outside the aes()

```{r}
# set aesthetic properties of your geom manually
ggplot(data=mpg) +
  geom_point(mapping=aes(x=displ, y=hwy), color = "blue")

```

Facets, split your plot into **facets**

```{r}
# facet_wrap() to split plots
ggplot(data=mpg) +
  geom_point(mapping=aes(x=displ, y=hwy)) +
  facet_wrap(~class, nrow=2)
# facet_grid() to split the combination of two variables
ggplot(data=mpg) +
  geom_point(mapping=aes(x=displ, y=hwy)) +
  facet_grid(drv~cyl)
```

### Line plots

A **geom** is the geometrical object that a plot uses to represent data. People often describe plots by the type of geom that the plot uses.

```{r}
# Point
ggplot(data=mpg) +
  geom_point(mapping=aes(x=displ, y=hwy))
# Smooth Lines
ggplot(data=mpg) +
  geom_smooth (mapping=aes(x=displ, y=hwy))
# For lines, you could set the linetype of a line
ggplot(data=mpg) +
  geom_smooth (mapping=aes(x=displ, y=hwy, linetype=drv))
# For lines, you could set group/color of a line
ggplot(data=mpg) +
  geom_smooth (mapping=aes(x=displ, y=hwy, group=drv))
ggplot(data=mpg) +
  geom_smooth (mapping=aes(x=displ, y=hwy, color=drv))
```

To display multiple geoms in the same plot, add multiple geom functions to [`ggplot()`](https://ggplot2.tidyverse.org/reference/ggplot.html):

-   Aesthetics appearing in a `geom` layer apply only to that layer.

-   If there are conflicting aesthetics in both the `ggplot()` function and the `geom` layer, the `geom` layer takes precedence.

```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) +
  geom_smooth(mapping = aes(x = displ, y = hwy))
# To avoid repetition by passing a set of mappings to ggplot()
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point() +
  geom_smooth()
# One plot different
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point(mapping = aes(color = class)) + 
  geom_smooth()
# Filter out part of the data
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point(mapping = aes(color = class)) + 
  geom_smooth(data = filter(mpg, class == "subcompact"), se = FALSE)
```

### Histograms

```{r}
head(diamonds)
ggplot(data=diamonds) +
  geom_bar(mapping=aes(x=cut))
# You might want to override the default mapping from transformed variables to aesthetics. For example, you might want to display a bar chart of proportion, rather than count:
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = stat(prop), group = 1))
# There’s one more piece of magic associated with bar charts. You can colour a bar chart using either the colour aesthetic, or, more usefully, fill:
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, colour = cut))
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = cut))
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity))
```

### Boxplots

```{r}
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + 
  geom_boxplot()
# coord_flip() switches the x and y axes.
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + 
  geom_boxplot() +
# handy way to flip the coordinates, instead of plotting the graph again.
  coord_flip()
```

## Tidy Data

```{r}
library(tidyr)
library(dplyr)
library(readr)
```

(chrome-[extension://efaidnbmnnnibpcajpcglclefindmkaj/https://vita.had.co.nz/papers/tidy-data.pdf](extension://efaidnbmnnnibpcajpcglclefindmkaj/https://vita.had.co.nz/papers/tidy-data.pdf))

### General Information

A dataset is a collection of values, usually either numbers or strings. Values are organised into two ways:

Every value belongs to a variable and an observation:

-   A variable contains all values that measure the same underlying attribute across units

-   An observation contains all values measured on the same units across attributes

|              | treatmenta | treatmentb |
|--------------|------------|------------|
| John Smith   | \-         | 2          |
| Jane Doe     | 16         | 11         |
| Mary Johnson | 3          | 1          |

Table 1. Imaginary experiment in a format seen in the wild

| Name         | treatments | result |
|--------------|------------|--------|
| John Smith   | a          | \-     |
| Jane Doe     | a          | 16     |
| Mary Johnson | a          | 3      |
| John Smith   | b          | 2      |
| Jane Doe     | b          | 11     |
| Mary Johnson | b          | 1      |

Table 2. Reorganization of table 1 to make values, variables and observations more clear

Table 2 is a tidy version of Table 1

General Rule of Thumb: It's easier to describe functional relationships between variables (z is a linear combination of x and y, density is the ratio of weight to volume) than between rows.

### Tidy Data

1\) Requirements:

-   Each variable forms a column

-   Each observation forms a row

-   Each type of observational unit forms a table

### Pivot_longer and Pivot_wider

[`pivot_longer()`](https://tidyr.tidyverse.org/reference/pivot_longer.html) and [`pivot_wider()`](https://tidyr.tidyverse.org/reference/pivot_wider.html) can take a data frame that specifies precisely how metadata stored in column names becomes data variables (and vice versa).

[`pivot_longer()`](https://tidyr.tidyverse.org/reference/pivot_longer.html) makes datasets **longer** by increasing the number of rows and decreasing the number of columns.

```{r}
# To begin with load the needed package
library(tidyverse)
# pivot_longer() Example 1: relig_income
head(relig_income)
relig_income %>%
  pivot_longer(
    cols = !religion, #cols describes which columns need to be reshaped. 
    names_to = "income", #names_to gives the name of the variable that will be created from the data stored in the column names
    values_to = "count" #gives the name of the variable that will be created from the data stored in the cell value
  )
# pivot_longer() Example 2: billboard
head(billboard)
billboard %>%
  pivot_longer(
    cols=starts_with("wk"),
    names_to = "Week",
    values_to = "rank",
    values_drop_na = TRUE
  )
billboard %>% 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    names_prefix = "wk",
    names_transform = as.integer,
    values_to = "rank",
    values_drop_na = TRUE,
  )
```

**`names_to = c(".value", "event")`** The use of **`.value`** here tells **`pivot_longer`** that part of the original column names should be used as the names of new columns in the output. It's a way of saying, "These parts of the original column names actually represent separate variables and should become separate columns in the long format."

```{r}
head(household)
household %>% 
  pivot_longer(
    cols = !family, 
    names_to = c(".value", "child"), 
    names_sep = "_", 
    values_drop_na = TRUE
  )
```

[`pivot_wider()`](https://tidyr.tidyverse.org/reference/pivot_wider.html) is the opposite of [`pivot_longer()`](https://tidyr.tidyverse.org/reference/pivot_longer.html): it makes a dataset **wider** by increasing the number of columns and decreasing the number of rows. It's relatively rare to need [`pivot_wider()`](https://tidyr.tidyverse.org/reference/pivot_wider.html) to make tidy data, but it's often useful for creating summary tables for presentation, or data in a format needed by other tools.

```{r}
head(fish_encounters)
fish_encounters %>%
  pivot_wider(
    names_from = station, #choose names that you want to switch to columns
    values_from = seen, #choose correspond values
    values_fill = 0 #fill these missing values in with zeros
  )
# id_cols = The id_cols parameter in the pivot_wider function can indeed be used to manage redundant columns in the process of reshaping data from long to wide format. 
```

### Others:

tidyr::seperate( ) could split a column of name into first_name and last_name

tidyr::unite( ) could re-unit first name and last name

```{r}
guest <- suppressMessages(read_csv("https://raw.githubusercontent.com/STAT545-UBC/Classroom/master/data/wedding/attend.csv"))
head(guest)
answer2.1 <- guest %>% 
  pivot_longer(cols      = c(-party, -name), 
               names_to  = c(".value", "event"),
               names_sep = "_")
answer2.2 <- answer2.1 %>% 
  separate(name, 
               into = c("first_name", "last_name"), 
               sep=" ")
head(answer2.2)
answer2.3 <- answer2.2 %>%
        unite(col = name, 
                 c("first_name", "last_name"), 
                 sep = " ")
head(answer2.3)
```

## Model-Fitting Paradigm in R

```{r}
library(tidyverse)
#there is a new tidyverse-like framework of packages to help with modelling.
#install.packages("tidymodels")
library(tidymodels)
library(gapminder)
```

The `broom` package has three crown functions that make it easy to extract each piece of information by converting your model into a tibble:

1.  `tidy`: extract statistical summaries about each "component" of the model.

2.  `augment`: add columns to the original data frame containing predictions.

3.  `glance`: extract statistical summaries about the model as a whole (a 1-row tibble).

```{r}
# method(formula, data, options)
my_lm <- lm(mpg~wt, data=mtcars)

# Use the tidy() function for a statistical summary of each component of your model, where each component gets a row in the output tibble.
tidy(my_lm)
# Statistic: This is the test statistic used to determine the statistical significance of the estimate. It is typically a t-statistic in regression analysis, which is calculated by dividing the estimate by its standard error.
# In the case of this regression output, the null hypothesis for the coefficient of wt would be that it is equal to zero, meaning wt has no effect on the dependent variable.

# Use the augment() function to make predictions on a dataset by augmenting predictions as a new column to your data. By default, augment() uses the dataset that was used to fit the model.
augment(my_lm) 
# .fitted 模型对每个观测值的预测值
# .resid：残差，即实际观测值与模型预测值之间的差异
# .cooksd：库克距离，一种衡量单个观测值对整个模型影响的统计量。
# .hat：杠杆值，反映了每个观测值对其预测值的影响程度。
# .sigma：排除了每个观测值后模型的标准误差。
# .std.resid：标准化残差，是残差除以其标准差的值。
# We can also predict on new datasets. Here are predictions of mpg for cars weighing 3, 4, and 5 thousand lbs.
augment(my_lm, newdata = tibble(wt=3:5))

# Use the glance() function to extract a summary of the model as a whole, in the form of a one-row tibble. This will give you information related to the model fit.
glance(my_lm)
# r.squared: The R-squared value is the proportion of variance in the dependent variable that can be predicted from the independent variables in the model. An R-squared value of 0.753 means that 75.3% of the variance is explained by the model.

# adj.r.squared: The adjusted R-squared value also reflects the proportion of variance explained by the model, but it adjusts for the number of predictors in the model. An adjusted R-squared of 0.745 is very close to the R-squared, suggesting that the model has a good number of predictors and not too many excess variables.

# sigma: This represents the standard deviation of the residuals, which are the differences between observed values and model-predicted values. A sigma of 3.05 indicates the average distance of the data points from the fitted line.

# statistic: This is likely the F-statistic, a measure of the overall significance of the regression model. An F-statistic of 91.4 is relatively high, which in this context, suggests that the model is a good fit for the data.

# p.value: This is the p-value associated with the F-statistic. A p-value of 1.29e-10 (very close to 0) strongly indicates that the model is statistically significant.

# df: This stands for "degrees of freedom." In the context of the F-statistic, it typically represents the number of independent variables in the model.

# logLik: The natural logarithm of the likelihood function for the model. The higher the log-likelihood, the better the model fits the data.

# AIC: The Akaike Information Criterion, which is used for model comparison. A lower AIC indicates a model that fits the data better when compared with other models.

# BIC: The Bayesian Information Criterion, similar to AIC but includes a penalty for the number of predictors. A lower BIC suggests a better model fit with a penalty for complexity.

```

If `broom::augment()` doesn\'t work, then the developer of the model almost surely made it so that the `predict()` function works (not part of the `broom` package). The `predict()` function typically takes the same format of the `augment()` function, but usually doesn\'t return a tibble.

```{r}
predict(my_lm) %>%
  unname() %>%
  head(5)
# unname() is used here to remove the names from the vector of predicted values, likely for reasons of simplicity, ease of further use, consistency, or formatting.
predict(my_lm, newdata = tibble(wt = 3:5)) %>% 
  unname()

# find the regression coefficients
coef(my_lm)
# Standard error of the residuals with sigma()
sigma(my_lm)

```

If you can\'t extract model information from built-in functions like `coef()` or `sigma()`, you can manually dig in to the model object. In most cases, a model object is just a list in disguise! (Lists are discussed in STAT 545B). You can therefore extract information like you would with any other list.

```{r}
names(my_lm)
my_lm$df.residual

# More info might be stored in yet another list after applying the summary() function:
summary(my_lm)
```

Plotting models with geom_smooth ()

```{r}
ggplot(mtcars, aes(x = wt, y = mpg)) +
    geom_point() +
    geom_smooth(method = "lm") 

# Let’s try fitting a linear model to this relationship
gapminder_Zimbabwe <- gapminder %>% 
  filter(country == "Zimbabwe")
gapminder_Zimbabwe %>% 
  ggplot(aes(year, lifeExp)) + 
  geom_point()

ggplot(gapminder_Zimbabwe, aes(year,lifeExp)) +
  geom_point() +
  geom_smooth(method = "lm", se = F)
# Found linear model may not be representative to the data, now we will try to fit a second degree polynomial and see what would that look like
ggplot(gapminder_Zimbabwe, aes(year,lifeExp)) +
  geom_point() +
  geom_smooth(method = "lm",
              formula = y ~ poly(x,2), 
              se = F)
```
